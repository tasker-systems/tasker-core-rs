//! Enhanced PGMQ client with notification capabilities
//!
//! This module provides PgmqNotifyClient, which wraps existing PGMQ clients
//! and integrates with database triggers for automatic notifications.
//!
//! **Key Change**: Notifications are now handled by database triggers (installed via migrations)
//! rather than application-level emission, simplifying this client significantly.

use pgmq::{Message, PGMQueue};
use serde::{Deserialize, Serialize};
use tracing::{debug, instrument};

use crate::config::PgmqNotifyConfig;
use crate::error::{PgmqNotifyError, Result};

/// Enhanced PGMQ client with trigger-based notifications
///
/// This client wraps the standard PGMQ client and relies on database triggers
/// (installed via migrations) to automatically emit notifications for queue operations.
pub struct PgmqNotifyClient {
    /// Underlying PGMQ client
    client: PGMQueue,
    /// Database connection pool for health checks and utilities
    pool: sqlx::PgPool,
    /// Configuration for notifications
    config: PgmqNotifyConfig,
}

impl PgmqNotifyClient {
    /// Create a new PgmqNotifyClient with trigger-based notifications
    ///
    /// **Note**: This client relies on database triggers installed via migrations
    /// to automatically emit notifications. Ensure you have run the migration
    /// generated by `pgmq-notify-cli generate-migration` first.
    pub async fn new(database_url: &str, config: PgmqNotifyConfig) -> Result<Self> {
        config.validate()?;

        let client = PGMQueue::new(database_url.to_string())
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        let pool = sqlx::PgPool::connect(database_url)
            .await
            .map_err(PgmqNotifyError::Database)?;

        Ok(Self {
            client,
            pool,
            config,
        })
    }

    /// Get the configuration
    pub fn config(&self) -> &PgmqNotifyConfig {
        &self.config
    }

    /// Get a reference to the underlying PGMQ client
    pub fn inner(&self) -> &PGMQueue {
        &self.client
    }

    /// Check if database connection is healthy
    pub async fn is_healthy(&self) -> bool {
        sqlx::query("SELECT 1").execute(&self.pool).await.is_ok()
    }

    /// Create a queue with automatic trigger-based notifications
    ///
    /// **Notifications**: Queue creation and message ready events are automatically
    /// emitted by database triggers installed via migrations.
    #[instrument(skip(self), fields(queue = %queue_name))]
    pub async fn create_queue(&mut self, queue_name: &str) -> Result<()> {
        debug!(
            "Creating queue: {} (notifications will be handled by triggers)",
            queue_name
        );

        // Create the queue using the underlying client
        // Database triggers will automatically:
        // 1. Emit queue_created notification when queue is added to pgmq.meta
        // 2. Install message_ready triggers on the new queue table
        self.client
            .create(queue_name)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!(
            "Successfully created queue: {} (triggers active for notifications)",
            queue_name
        );
        Ok(())
    }

    /// Send a message to a queue
    ///
    /// Note: Message ready notifications are handled automatically by database triggers.
    /// This method only sends the message to PGMQ - the trigger will emit the notification.
    #[instrument(skip(self, message), fields(queue = %queue_name))]
    pub async fn send<T>(&mut self, queue_name: &str, message: &T) -> Result<i64>
    where
        T: Serialize + Send + Sync,
    {
        debug!("Sending message to queue: {}", queue_name);

        // Send the message using the underlying client
        // The database trigger will automatically emit the message_ready notification
        let msg_id = self
            .client
            .send(queue_name, message)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!("Successfully sent message {} to queue: {} (notification will be triggered automatically)", msg_id, queue_name);
        Ok(msg_id)
    }

    /// Send a message with delay
    ///
    /// Note: Message ready notifications are handled automatically by database triggers
    /// when the delayed message becomes available.
    #[instrument(skip(self, message), fields(queue = %queue_name, delay = %delay_seconds))]
    pub async fn send_delay<T>(
        &mut self,
        queue_name: &str,
        message: &T,
        delay_seconds: i64,
    ) -> Result<i64>
    where
        T: Serialize + Send + Sync,
    {
        debug!(
            "Sending delayed message to queue: {} (delay: {}s)",
            queue_name, delay_seconds
        );

        // Send the delayed message using the underlying client
        // The database trigger will automatically emit the notification when the message becomes available
        let msg_id = self
            .client
            .send_delay(queue_name, message, delay_seconds as u64)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!("Successfully sent delayed message {} to queue: {} (notification will be triggered when available)", msg_id, queue_name);
        Ok(msg_id)
    }

    /// Read messages from a queue
    #[instrument(skip(self), fields(queue = %queue_name, vt = %vt, qty = %qty))]
    pub async fn read<T>(&mut self, queue_name: &str, vt: i32, qty: i32) -> Result<Vec<Message<T>>>
    where
        T: for<'de> Deserialize<'de> + Send + Sync,
    {
        debug!(
            "Reading {} messages from queue: {} (vt: {})",
            qty, queue_name, vt
        );

        let message = self
            .client
            .read::<T>(queue_name, Some(vt))
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        let messages = match message {
            Some(msg) => vec![msg],
            None => vec![],
        };

        debug!(
            "Successfully read {} messages from queue: {}",
            messages.len(),
            queue_name
        );
        Ok(messages)
    }

    /// Delete a message from a queue
    #[instrument(skip(self), fields(queue = %queue_name, msg_id = %msg_id))]
    pub async fn delete(&mut self, queue_name: &str, msg_id: i64) -> Result<u64> {
        debug!("Deleting message {} from queue: {}", msg_id, queue_name);

        let deleted = self
            .client
            .delete(queue_name, msg_id)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!(
            "Successfully deleted {} messages from queue: {}",
            deleted, queue_name
        );
        Ok(deleted)
    }

    /// Archive a message (move to archive table)
    #[instrument(skip(self), fields(queue = %queue_name, msg_id = %msg_id))]
    pub async fn archive(&mut self, queue_name: &str, msg_id: i64) -> Result<u64> {
        debug!("Archiving message {} from queue: {}", msg_id, queue_name);

        let archived = self
            .client
            .archive(queue_name, msg_id)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!(
            "Successfully archived {} messages from queue: {}",
            archived, queue_name
        );
        Ok(archived)
    }

    // Note: Drop queue method not available in the current PGMQ version

    /// Purge all messages from a queue
    #[instrument(skip(self), fields(queue = %queue_name))]
    pub async fn purge_queue(&mut self, queue_name: &str) -> Result<u64> {
        debug!("Purging queue: {}", queue_name);

        let purged = self
            .client
            .purge(queue_name)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        debug!(
            "Successfully purged {} messages from queue: {}",
            purged, queue_name
        );
        Ok(purged)
    }

    // Note: Metrics methods not available in the current PGMQ version
    // They can be added when the API supports them

    /// Pop a single message from a queue (read + delete)
    #[instrument(skip(self), fields(queue = %queue_name))]
    pub async fn pop<T>(&mut self, queue_name: &str) -> Result<Option<Message<T>>>
    where
        T: for<'de> Deserialize<'de> + Send + Sync,
    {
        debug!("Popping message from queue: {}", queue_name);

        let message = self
            .client
            .pop::<T>(queue_name)
            .await
            .map_err(|e| PgmqNotifyError::Generic(e.into()))?;

        if message.is_some() {
            debug!("Successfully popped message from queue: {}", queue_name);
        } else {
            debug!("No messages available to pop from queue: {}", queue_name);
        }

        Ok(message)
    }

    /// Read a specific message ID from a queue with visibility timeout
    ///
    /// This method uses a custom SQL function to safely read a specific message
    /// and set a visibility timeout to prevent race conditions. This is critical
    /// for event-driven processing where we need to claim the exact message
    /// that triggered the notification.
    #[instrument(skip(self), fields(queue = %queue_name, msg_id = %msg_id, vt = %vt_seconds))]
    pub async fn read_specific_message<T>(
        &mut self,
        queue_name: &str,
        msg_id: i64,
        vt_seconds: i32,
    ) -> Result<Option<Message<T>>>
    where
        T: for<'de> Deserialize<'de> + Send + Sync,
    {
        debug!(
            "Reading specific message {} from queue: {} (vt: {})",
            msg_id, queue_name, vt_seconds
        );

        let row = sqlx::query!(
            "SELECT * FROM pgmq_read_specific_message($1, $2, $3)",
            queue_name,
            msg_id,
            vt_seconds
        )
        .fetch_optional(&self.pool)
        .await
        .map_err(PgmqNotifyError::Database)?;

        match row {
            Some(row) => {
                // Extract required fields, returning None if any are missing
                let message_json = row.message.ok_or_else(|| {
                    PgmqNotifyError::Generic(anyhow::anyhow!("Message content is null"))
                })?;
                let msg_id_val = row.msg_id.ok_or_else(|| {
                    PgmqNotifyError::Generic(anyhow::anyhow!("Message ID is null"))
                })?;
                let vt_val = row.vt.ok_or_else(|| {
                    PgmqNotifyError::Generic(anyhow::anyhow!("Visibility timeout is null"))
                })?;
                let read_ct_val = row.read_ct.ok_or_else(|| {
                    PgmqNotifyError::Generic(anyhow::anyhow!("Read count is null"))
                })?;
                let enqueued_at_val = row.enqueued_at.ok_or_else(|| {
                    PgmqNotifyError::Generic(anyhow::anyhow!("Enqueued timestamp is null"))
                })?;

                // Deserialize the message content
                let message_data: T =
                    serde_json::from_value(message_json).map_err(PgmqNotifyError::Serialization)?;

                let message = Message {
                    msg_id: msg_id_val,
                    vt: vt_val,
                    read_ct: read_ct_val,
                    enqueued_at: enqueued_at_val,
                    message: message_data,
                };

                debug!(
                    "Successfully read specific message {} from queue: {}",
                    msg_id, queue_name
                );
                Ok(Some(message))
            }
            None => {
                debug!("Specific message {} not available from queue: {} (already claimed or doesn't exist)", msg_id, queue_name);
                Ok(None)
            }
        }
    }

    /// Delete a specific message by ID (typically after successful processing)
    ///
    /// This method uses a custom SQL function to safely delete a specific message
    /// after it has been successfully processed to prevent reprocessing.
    #[instrument(skip(self), fields(queue = %queue_name, msg_id = %msg_id))]
    pub async fn delete_specific_message(&mut self, queue_name: &str, msg_id: i64) -> Result<bool> {
        debug!(
            "Deleting specific message {} from queue: {}",
            msg_id, queue_name
        );

        let result = sqlx::query!(
            "SELECT pgmq_delete_specific_message($1, $2) as deleted",
            queue_name,
            msg_id
        )
        .fetch_one(&self.pool)
        .await
        .map_err(PgmqNotifyError::Database)?;

        let deleted = result.deleted.unwrap_or(false);

        if deleted {
            debug!(
                "Successfully deleted specific message {} from queue: {}",
                msg_id, queue_name
            );
        } else {
            debug!(
                "Specific message {} was not found for deletion from queue: {}",
                msg_id, queue_name
            );
        }

        Ok(deleted)
    }

    /// Extend visibility timeout for a specific message
    ///
    /// This method uses a custom SQL function to extend the visibility timeout
    /// of a specific message if processing takes longer than expected.
    #[instrument(skip(self), fields(queue = %queue_name, msg_id = %msg_id, additional_vt = %additional_vt_seconds))]
    pub async fn extend_vt_specific_message(
        &mut self,
        queue_name: &str,
        msg_id: i64,
        additional_vt_seconds: i32,
    ) -> Result<bool> {
        debug!(
            "Extending VT for specific message {} in queue: {} (+{}s)",
            msg_id, queue_name, additional_vt_seconds
        );

        let result = sqlx::query!(
            "SELECT pgmq_extend_vt_specific_message($1, $2, $3) as extended",
            queue_name,
            msg_id,
            additional_vt_seconds
        )
        .fetch_one(&self.pool)
        .await
        .map_err(PgmqNotifyError::Database)?;

        let extended = result.extended.unwrap_or(false);

        if extended {
            debug!(
                "Successfully extended VT for specific message {} in queue: {}",
                msg_id, queue_name
            );
        } else {
            debug!(
                "Specific message {} was not found for VT extension in queue: {}",
                msg_id, queue_name
            );
        }

        Ok(extended)
    }
}

/// Factory for creating PgmqNotifyClient instances
pub struct PgmqNotifyClientFactory;

impl PgmqNotifyClientFactory {
    /// Create a client with trigger-based notifications
    ///
    /// **Note**: Requires database triggers to be installed via migrations.
    /// Use `pgmq-notify-cli generate-migration` to create the required migration.
    pub async fn new(database_url: &str, config: PgmqNotifyConfig) -> Result<PgmqNotifyClient> {
        PgmqNotifyClient::new(database_url, config).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::PgmqNotifyConfig;
    use serde::{Deserialize, Serialize};

    #[derive(Serialize, Deserialize, Debug, PartialEq)]
    struct TestMessage {
        content: String,
        id: i32,
    }

    #[test]
    fn test_client_configuration() {
        let config = PgmqNotifyConfig::default();

        // Test configuration validation
        assert!(config.validate().is_ok());
    }

    #[test]
    fn test_message_serialization() {
        let message = TestMessage {
            content: "Hello, PGMQ!".to_string(),
            id: 42,
        };

        let json = serde_json::to_string(&message).unwrap();
        let deserialized: TestMessage = serde_json::from_str(&json).unwrap();

        assert_eq!(message, deserialized);
    }

    #[test]
    fn test_namespace_extraction() {
        let config = PgmqNotifyConfig::default();

        assert_eq!(config.extract_namespace("orders_queue").unwrap(), "orders");
        assert_eq!(
            config.extract_namespace("inventory_queue").unwrap(),
            "inventory"
        );
        assert_eq!(
            config.extract_namespace("unknown_format").unwrap(),
            "default"
        );
    }

    #[test]
    fn test_client_factory() {
        let config = PgmqNotifyConfig::default();

        // Verify the factory method exists and config is valid
        assert!(config.validate().is_ok());
    }

    // Note: Full integration tests with actual database operations
    // should be in separate integration test modules with proper database setup.
    // These tests would verify that triggers are working correctly.
}
